---
title: "RandomForest"
author: "Sivhuo Prak (Siv)"
date: "11/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)         # for reading in data, graphing, and cleaning
library(tidymodels)        # for modeling ... tidily
library(stacks)            # for stacking models
library(glmnet)            # for regularized regression, including LASSO
library(ranger)            # for random forest model
library(kknn)              # for knn model
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(rmarkdown)         # for paged tables
theme_set(theme_minimal()) # my favorite ggplot2 theme :)
```

```{r}
library(randomForest)
library(mlbench)
library(caret)
library(e1071)
```

## Final Data 

```{r}
final_data 

# final_data <- final_data %>% 
#   filter(YEAR<2021) %>% 
#   select(-YEAR,-COMPANY,-PRICE,-Sell,-Name,-GDP,-M1SL,-Earnings_next_year) 
```

## Spliting Data 
```{r}
set.seed(327) #for reproducibility

# Randomly assigns 75% of the data to training.
data_split <- initial_split(final_data, 
                             prop = .75)
data_training <- training(data_split)
data_testing <- testing(data_split)
data_training 
```

```{r}
#Tuning mtry parameter 

tuneGrid <- data.frame(
  .mtry = c(10, 15, 20, 25, 30, 35, 40, 45, 50, 55),
  .splitrule = "variance",
  .min.node.size = 5
)

model <- train(
  PROFIT ~ .,
  tuneGrid = tuneGrid, 
  data = data_training,
  method = "ranger", 
  trControl = trainControl(method = "cv", 
                           number = 5, 
                           verboseIter = FALSE) 
)
model
```

## Create the recipe 

```{r}
# do I need to normalize? 
ranger_recipe <-
  recipe(PROFIT ~ ., #short-cut, . = all other vars
                       data = data_training) %>%
  step_filter(YEAR<2021) %>% 
  # remove the unwanted variables
  step_rm(YEAR,COMPANY,PRICE,Sell,Name,GDP,M1SL,Earnings_next_year,Sector) %>% 
  # add PE 
  step_mutate(PE = `MARKET CAP`/EARNINGS)
```

```{r}
ranger_spec <- 
  rand_forest(mtry = 10, 
              min_n = 10, 
              trees = 200) %>% 
  set_mode("regression") %>% 
  set_engine("ranger")
```

```{r}
ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec)
```

```{r}
ranger_fit <- ranger_workflow %>% 
  fit(data_training)

ranger_fit
```

```{r}
# OOB error (MSE) ... 
ranger_fit$fit$fit$fit$prediction.error
#OOB RMSE
sqrt(ranger_fit$fit$fit$fit$prediction.error)
# R squared
ranger_fit$fit$fit$fit$r.squared
```

```{r}
set.seed(1211) # for reproducibility
data_cv <- vfold_cv(data_training, v = 5)

metric <- metric_set(rmse)
ctrl_res <- control_stack_resamples()

ranger_cv <- ranger_workflow %>% 
  fit_resamples(data_cv, 
                metrics = metric,
                control = ctrl_res)

# Evaluation metrics averaged over all folds:
collect_metrics(ranger_cv)
```

```{r}
ranger_prediction <- predict(
  ranger_fit,
  new_data = data_training)

ranger_training_pred<-data_training %>% 
  mutate(.pred = ranger_prediction$.pred)
  

ranger_training_pred %>%
  ggplot(aes(x = PROFIT,
             y = .pred)) +
  geom_point(alpha = .5,
             size = .5) +
  geom_smooth(se = FALSE) +
  geom_abline(slope = 1,
              intercept = 0,
              color = "darkred") +
  geom_text(aes(label = Name),data = ranger_training_pred %>% filter(PROFIT>200) )+
  labs(x = "Actual Return",
       y = "Predicted Return")
```






